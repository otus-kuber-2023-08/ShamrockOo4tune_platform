image:
  name: registry.gitlab.com/gitlab-org/gitlab-build-images:terraform
  entrypoint:
    - '/usr/bin/env'
    - 'PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'

cache:
  paths:
    - .terraform

variables:
  YC_SERVICE_ACCOUNT_KEY_FILE: "/home/anduser/yc-terraform/key.json"

stages: 
  - infrastructure_provisioning 
  - bastion_configuration
  - generate-inventory
  - deploy
  - gitops
  
before_script:
  - apk add gnupg
  - mkdir -p /home/anduser/yc-terraform
  - cat $YC_KEY > /home/anduser/yc-terraform/key.json
  - cd ./kubernetes-project/terraform
  - cat $TFVARS > terraform.tfvars
  - |
    cat <<EOF >> ~/.terraformrc
    provider_installation {
      network_mirror {
        url = "https://terraform-mirror.yandexcloud.net/"
        include = ["registry.terraform.io/*/*"]
      }
      direct {
        exclude = ["registry.terraform.io/*/*"]
      }
    }
    EOF
  - terraform init -reconfigure

validate_and_plan:
  stage: infrastructure_provisioning
  script: 
    - terraform validate
    - terraform plan -out="planfile"
  after_script:
    - >
      gpg \
        --symmetric \
        --batch \
        --yes \
        --passphrase ${ARTIFACT_ENCRYPTION_PASSPHRASE} \
        -o ./kubernetes-project/terraform/planfile.gpg \
        -c ./kubernetes-project/terraform/planfile
  artifacts:
    paths:
      - kubernetes-project/terraform/planfile.gpg
    expire_in: 1800 seconds

apply:
  stage: infrastructure_provisioning    
  needs:
    - job: validate_and_plan
      artifacts: true
  script:
    - >
      echo ${ARTIFACT_ENCRYPTION_PASSPHRASE} | gpg \
        --batch \
        --always-trust \
        --yes \
        --passphrase-fd 0 \
        -d \
        -o planfile planfile.gpg
    - terraform apply -auto-approve "planfile"
    - terraform output -json > outputs.json 
  when: manual
  after_script:
    - >
      gpg \
        --symmetric \
        --batch \
        --yes \
        --passphrase ${ARTIFACT_ENCRYPTION_PASSPHRASE} \
        -o ./kubernetes-project/terraform/ansible_rsa.gpg \
        -c ./kubernetes-project/terraform/ansible_rsa
    - >
      gpg \
        --symmetric \
        --batch \
        --yes \
        --passphrase ${ARTIFACT_ENCRYPTION_PASSPHRASE} \
        -o ./kubernetes-project/terraform/outputs.json.gpg \
        -c ./kubernetes-project/terraform/outputs.json
  artifacts:
    paths:
      - kubernetes-project/terraform/ansible_rsa.gpg
      - kubernetes-project/terraform/outputs.json.gpg
    expire_in: 10800 seconds

configure-bastion:
  stage: bastion_configuration
  image: alpine
  needs:
    - job: apply
      artifacts: true
  when: manual
  before_script:
    - cd ./kubernetes-project/terraform
    - apk update; apk add gnupg jq openssh
    - >
      echo ${ARTIFACT_ENCRYPTION_PASSPHRASE} | gpg \
        --batch \
        --always-trust \
        --yes \
        --passphrase-fd 0 \
        -d \
        -o ansible_rsa ansible_rsa.gpg
    - >
      echo ${ARTIFACT_ENCRYPTION_PASSPHRASE} | gpg \
        --batch \
        --always-trust \
        --yes \
        --passphrase-fd 0 \
        -d \
        -o outputs.json outputs.json.gpg
    - chmod 0400 ansible_rsa
    - export BASTION_IP=$(cat outputs.json | jq -r .bastion_public_ip.value)
  script:
    - >
      scp -o "StrictHostKeyChecking no" -i ansible_rsa \
        ansible_rsa \
        ansible@${BASTION_IP}:/home/ansible/.ssh/id_rsa || true 
    - >
      ssh -T -o "StrictHostKeyChecking no" -i ansible_rsa -l ansible \
        ${BASTION_IP} "\
          sudo apt-get -y update && \
          sudo DEBIAN_FRONTEND=noninteractive apt-get -y install \
            software-properties-common \
            gnupg2 \
            git \
            curl \
            python3-pip \
            ansible-core \
            jq \
            ceph-common \
            bash-completion; \
          sudo mkdir -p /root/ansible; \
          sudo touch /root/ansible/ansible.log \
        "
    - >
      ssh -T -o "StrictHostKeyChecking no" -i ansible_rsa -l ansible \
        ${BASTION_IP} "sudo pip install virtualenv ansible-core"
    - >
      ssh -T -o "StrictHostKeyChecking no" -i ansible_rsa -l ansible \
        ${BASTION_IP} "\
          git clone https://github.com/ceph/ceph-ansible.git; \
          cd ceph-ansible; \
          git checkout stable-7.0 \
        "
    - >
      ssh -T -o "StrictHostKeyChecking no" -i ansible_rsa -l ansible \
        ${BASTION_IP} "\
          git clone https://github.com/kubernetes-sigs/kubespray.git; \
          cd kubespray; \
          cp -rfp inventory/sample inventory/mycluster \
        "

generate-inventory:
  stage: generate-inventory
  image: alpine
  needs:
    - job: configure-bastion
    - job: apply
      artifacts: true
  when: manual
  before_script:
    - cd ./kubernetes-project
    - apk update; apk add gnupg jq openssh gettext
    - >
      echo ${ARTIFACT_ENCRYPTION_PASSPHRASE} | gpg \
        --batch \
        --always-trust \
        --yes \
        --passphrase-fd 0 \
        -d \
        -o ansible_rsa ./terraform/ansible_rsa.gpg
    - >
      echo ${ARTIFACT_ENCRYPTION_PASSPHRASE} | gpg \
        --batch \
        --always-trust \
        --yes \
        --passphrase-fd 0 \
        -d \
        -o outputs.json ./terraform/outputs.json.gpg
    - chmod 0400 ansible_rsa
    - >
      export BASTION_IP=$( \
        cat outputs.json | jq -r .bastion_public_ip.value \
      )
    - >
      export PLATFORM_INGRESS_IP=$( \
        cat outputs.json | jq -r .platform_ingress_ip.value \
      )
    - >
      export MASTER1_IP=$( \
        cat outputs.json | jq -r .master_nodes_private_ips.value[0] \
      )
    - >
      export MASTER2_IP=$( \
        cat outputs.json | jq -r .master_nodes_private_ips.value[1] \
      )
    - >
      export MASTER3_IP=$( \
        cat outputs.json | jq -r .master_nodes_private_ips.value[2] \
      )
    - >
      export WORKER1_IP=$( \
        cat outputs.json | jq -r .worker_nodes_private_ips.value[0] \
      )
    - >
      export WORKER2_IP=$( \
        cat outputs.json | jq -r .worker_nodes_private_ips.value[1] \
      )
    - >
      export WORKER3_IP=$( \
        cat outputs.json | jq -r .worker_nodes_private_ips.value[2] \
      )
    - >
      export CEPH1_IP=$( \
        cat outputs.json | jq -r .ceph1_private_ip.value \
      )
    - >
      export CEPH2_IP=$( \
        cat outputs.json | jq -r .ceph2_private_ip.value \
      )
    - >
      export CEPH3_IP=$( \
        cat outputs.json | jq -r .ceph3_private_ip.value \
      )
  script:
    - >
      for i in 1 2 3 ; do
        sed -i \
        "s/ceph${i}_ip/$(cat outputs.json | \
          jq -r .ceph${i}_private_ip.value)/" \
        ceph/inventory.ini
      done
    - >
      scp -o 'StrictHostKeyChecking no' -i ansible_rsa \
        ceph/inventory.ini \
        ansible@${BASTION_IP}:/home/ansible/ceph-ansible/inventory.ini
    - >
      scp -o 'StrictHostKeyChecking no' -i ansible_rsa \
        ceph/site.yml \
        ansible@${BASTION_IP}:/home/ansible/ceph-ansible/site.yml
    - >
      scp -o 'StrictHostKeyChecking no' -i ansible_rsa \
        ceph/all.yml \
        ansible@${BASTION_IP}:/home/ansible/ceph-ansible/group_vars/all.yml
    - > 
      scp -o 'StrictHostKeyChecking no' -i ansible_rsa \
        ceph/osds.yml \
        ansible@${BASTION_IP}:/home/ansible/ceph-ansible/group_vars/osds.yml
    - >
      for i in 1 2 3 ; do
        MASTER_IP=MASTER${i}_IP
        if [ "${!MASTER_IP}" == 'null' ]; then
          echo "INFO: MASTER${i}_IP is 'null', rm it from hosts" 
          sed -i '/master${i}/d' k8s/hosts.yaml
        else
          echo "INFO: Substituting MASTER${i}_IP in hosts"
          sed -i 's/master${i}_ip/${!MASTER_IP}/' k8s/hosts.yaml
        fi
        WORKER_IP=WORKER${i}_IP
        if [ "${!WORKER_IP}" == 'null' ]; then
          echo "INFO: WORKER${i}_IP is 'null', rm it from hosts" 
          sed -i '/worker${i}/d' k8s/hosts.yaml
        else
          echo "INFO: Substituting WORKER${i}_IP in hosts"
          sed -i 's/worker${i}_ip/${!WORKER_IP}/' k8s/hosts.yaml
        fi
      done        
    - >  
      envsubst '$SELECTEL_API_TOKEN' < argocd/selectel-api-token.yml.template \
        > argocd/selectel-api-token.yml; \
      envsubst '$ARGOCD_ADMIN_PASSWORD' < k8s/addons.yml.template \
        > k8s/addons.yml; \
      envsubst '$PLATFORM_INGRESS_IP' < k8s/k8s-cluster.yml.template \
        > k8s/k8s-cluster.yml
    - >
      scp -o "StrictHostKeyChecking no" -i ansible_rsa \
        k8s/hosts.yaml \
        ansible@${BASTION_IP}:~/kubespray/inventory/mycluster/hosts.yaml
    - >
      scp -o "StrictHostKeyChecking no" -i ansible_rsa \
        k8s/addons.yml \
        ansible@${BASTION_IP}:~/kubespray/inventory/mycluster/group_vars/k8s_cluster/addons.yml
    - >
      scp -o "StrictHostKeyChecking no" -i ansible_rsa \
        k8s/all.yml \
        ansible@${BASTION_IP}:~/kubespray/inventory/mycluster/group_vars/all/all.yml
    - >
      scp -o "StrictHostKeyChecking no" -i ansible_rsa \
        k8s/k8s-cluster.yml \
        ansible@${BASTION_IP}:~/kubespray/inventory/mycluster/group_vars/k8s_cluster/k8s-cluster.yml
    - >
      scp -o "StrictHostKeyChecking no" -i ansible_rsa \
        argocd/selectel-api-token.yml \
        ansible@${BASTION_IP}:~/argocd/selectel-api-token.yaml

deploy-ceph:
  stage: deploy
  image: alpine
  needs:
    - job: generate-inventory
    - job: apply
      artifacts: true
  when: manual
  before_script:
    - cd ./kubernetes-project
    - apk update; apk add gnupg jq openssh
    - >
      echo ${ARTIFACT_ENCRYPTION_PASSPHRASE} | gpg \
        --batch \
        --always-trust \
        --yes \
        --passphrase-fd 0 \
        -d \
        -o ansible_rsa ./terraform/ansible_rsa.gpg
    - >
      echo ${ARTIFACT_ENCRYPTION_PASSPHRASE} | gpg \
        --batch \
        --always-trust \
        --yes \
        --passphrase-fd 0 \
        -d \
        -o outputs.json ./terraform/outputs.json.gpg
    - chmod 0400 ansible_rsa
    - export BASTION_IP=$(cat outputs.json | jq -r .bastion_public_ip.value)
  script:
    - >
      ssh -T -o "StrictHostKeyChecking no" -i ansible_rsa -l ansible \
        $BASTION_IP " \
          cd ~/ceph-ansible; \
          sudo virtualenv ../ceph-ansible; \
          source bin/activate; \
          sudo ansible-playbook -i inventory.ini ./site.yml; deactivate \
        "
    - >
      ssh -T -o "StrictHostKeyChecking no" -i ansible_rsa -l ansible \
        $BASTION_IP " \
          ssh -o 'StrictHostKeyChecking no' ceph1.ru-central1.internal \
          'sudo ceph config set mon auth_allow_insecure_global_id_reclaim false' \
        "
    - >
      ssh -T -o "StrictHostKeyChecking no" -i ansible_rsa -l ansible \
        $BASTION_IP "sudo mkdir -p -m 755 /etc/ceph"
    - >
      ssh -T -o "StrictHostKeyChecking no" -i ansible_rsa -l ansible \
        $BASTION_IP " \
          ssh ceph1.ru-central1.internal \
          'sudo ceph config generate-minimal-conf' | \
          sudo tee /etc/ceph/ceph.conf \
        "
    - >
      ssh -T -o "StrictHostKeyChecking no" -i ansible_rsa -l ansible \
        $BASTION_IP "sudo chmod 644 /etc/ceph/ceph.conf"
    - >
      ssh -T -o "StrictHostKeyChecking no" -i ansible_rsa -l ansible \
        $BASTION_IP " \
          ssh ceph1.ru-central1.internal \
          'sudo ceph fs authorize cephfs client.kube / rw' | \
          sudo tee /etc/ceph/ceph.client.kube.keyring \
        "
    - >
      ssh -T -o "StrictHostKeyChecking no" -i ansible_rsa -l ansible \
        $BASTION_IP "sudo chmod 600 /etc/ceph/ceph.client.kube.keyring"
    - >
      ssh -T -o 'StrictHostKeyChecking no' -i ansible_rsa -l ansible \
        $BASTION_IP "sudo mkdir -p /mnt/mycephfs"
    - >
      ssh -T -o 'StrictHostKeyChecking no' -i ansible_rsa -l ansible \
        $BASTION_IP " \
          ssh ceph1.ru-central1.internal \
          'sudo ceph auth get-key client.kube' | \
          sudo tee /etc/ceph/kube.key \
        "
    - >
      ssh -T -o "StrictHostKeyChecking no" -i ansible_rsa -l ansible \
        $BASTION_IP "sudo chmod 600 /etc/ceph/kube.key"
    - >
      ssh -T -o 'StrictHostKeyChecking no' -i ansible_rsa -l ansible \
        $BASTION_IP " \
          ssh ceph1.ru-central1.internal \
          'sudo ceph fs subvolumegroup create cephfs csi' \
        "
    - >
      export CEPH_FSID=$( \
        ssh -T -o 'StrictHostKeyChecking no' -i ansible_rsa -l ansible \
        $BASTION_IP "ssh ceph1.ru-central1.internal 'sudo ceph fsid'" \
      )
    - >
      export CEPH_ADMIN_KEY=$( \
        ssh -T -o 'StrictHostKeyChecking no' -i ansible_rsa -l ansible \
        $BASTION_IP "ssh ceph1.ru-central1.internal \
        'sudo ceph auth get client.admin'" | grep 'key =' | awk '{ print $3 }' \
      )
    - >
      export CEPH_KUBE_KEY=$( \
        ssh -T -o 'StrictHostKeyChecking no' -i ansible_rsa -l ansible \
        $BASTION_IP "ssh ceph1.ru-central1.internal \
        'sudo ceph auth get-key client.kube'" \
      )
    - >
      ssh -T -o 'StrictHostKeyChecking no' -i ansible_rsa -l ansible \
        $BASTION_IP " \
          echo 'kube@.cephfs=/ /mnt/mycephfs ceph mon_addr=ceph1.ru-central1.internal:6789/ceph2.ru-central1.internal:6789/ceph3.ru-central1.internal:6789,secretfile=/etc/ceph/kube.key,noatime,_netdev 0 0' | \
          sudo tee -a /etc/fstab \
        "
    - >
      ssh -T -o 'StrictHostKeyChecking no' -i ansible_rsa -l ansible \
        $BASTION_IP 'sudo mount /mnt/mycephfs'
    - >
      ssh -T -o 'StrictHostKeyChecking no' -i ansible_rsa -l ansible \
        $BASTION_IP "df -h"
    - >
      for WORKER_IP in ${WORKER1_IP} ${WORKER2_IP} ${WORKER3_IP} ; do
        if [ "${WORKER_IP}" == 'null' ]; then
          echo "INFO: skipping null WORKER_IP" 
        else
          ssh -T -o 'StrictHostKeyChecking no' -i ansible_rsa -l ansible \
            $BASTION_IP " \
              ssh -T -o 'StrictHostKeyChecking no' ${WORKER_IP} \
              'sudo mkdir -p /etc/ceph; sudo chown ansible:ansible /etc/ceph'; \
              ssh -T -o 'StrictHostKeyChecking no' ${WORKER_IP} \
              'sudo mkdir -p /mnt/mycephfs'; \
              scp -r -o 'StrictHostKeyChecking no' /etc/ceph/* \
              ${WORKER_IP}:/etc/ceph/; \
              ssh -T -o 'StrictHostKeyChecking no' ${WORKER_IP} \
              'echo \'kube@.cephfs=/ /mnt/mycephfs ceph mon_addr=ceph1.ru-central1.internal:6789/ceph2.ru-central1.internal:6789/ceph3.ru-central1.internal:6789,secretfile=/etc/ceph/kube.key,noatime,_netdev 0 0\' | sudo tee -a /etc/fstab'; \
              ssh -T -o "StrictHostKeyChecking no" ${WORKER_IP} \
              'sudo mount /mnt/mycephfs'; \
              ssh -T -o "StrictHostKeyChecking no" ${WORKER_IP} \
              'df -h'
            "       
        fi
      done

deploy-k8s:
  stage: deploy
  image: alpine
  needs:
    - job: generate-inventory
    - job: deploy-ceph
    - job: apply
      artifacts: true
  when: manual
  before_script:
    - cd ./kubernetes-project
    - apk update; apk add gnupg jq openssh
    - >
      echo ${ARTIFACT_ENCRYPTION_PASSPHRASE} | gpg \
        --batch \
        --always-trust \
        --yes \
        --passphrase-fd 0 \
        -d \
        -o ansible_rsa  ./terraform/ansible_rsa.gpg
    - >
      echo ${ARTIFACT_ENCRYPTION_PASSPHRASE} | gpg \
        --batch \
        --always-trust \
        --yes \
        --passphrase-fd 0 \
        -d \
        -o outputs.json ./terraform/outputs.json.gpg
    - chmod 0400 ansible_rsa
    - export BASTION_IP=$(cat outputs.json | jq -r .bastion_public_ip.value)
  script:
    - >
      ssh -T -o 'StrictHostKeyChecking no' -i ansible_rsa -l ansible \
        ${BASTION_IP} " \
          cd ~/kubespray; \
          source bin/activate; \
          sudo ansible-playbook \
            -i inventory/mycluster/hosts.yaml \
            --become \
            --become-user=root \
            --user=ansible \
            --key-file=/home/ansible/.ssh/id_rsa \
            cluster.yml; \
          deactivate \
        "
  after_script:
    - >
      export BASTION_IP=$( \
        cat ./kubernetes-project/outputs.json | \
        jq -r .bastion_public_ip.value \
      )
    - >
      ssh -T -o 'StrictHostKeyChecking no' -i ansible_rsa -l ansible \
        ${BASTION_IP} " \
          mkdir ~/.kube; \
          sudo cp ~/kubespray/inventory/mycluster/artifacts/admin.conf \
          ~/.kube/config; \
          sudo cp ~/kubespray/inventory/mycluster/artifacts/kubectl \
          /usr/local/bin/; \
          sudo chown ansible:ansible ~/.kube/config; \
          echo 'source <(kubectl completion bash)' >> ~/.bashrc; \
          echo 'alias k=kubectl' >> ~/.bashrc; \
          echo 'complete -o default -F __start_kubectl k' >> ~/.bashrc; \
        "
    - >
      ssh -T -o 'StrictHostKeyChecking no' -i ansible_rsa -l ansible \
        ${BASTION_IP} "k get nodes"

kickstart-gitops:
  stage: gitops
  image: alpine
  needs:
    - job: generate-inventory
    - job: deploy-ceph
    - job: apply
    - job: deploy-k8s
      artifacts: true
  when: manual
  before_script:
    - cd ./kubernetes-project
    - apk update; apk add gnupg jq openssh
    - >
      echo ${ARTIFACT_ENCRYPTION_PASSPHRASE} | gpg \
        --batch \
        --always-trust \
        --yes \
        --passphrase-fd 0 \
        -d \
        -o ansible_rsa  ./terraform/ansible_rsa.gpg
    - >
      echo ${ARTIFACT_ENCRYPTION_PASSPHRASE} | gpg \
        --batch \
        --always-trust \
        --yes \
        --passphrase-fd 0 \
        -d \
        -o ./kubernetes-project/outputs.json \
        ./kubernetes-project/terraform/outputs.json.gpg
    - chmod 0400 ansible_rsa
    - export BASTION_IP=$(cat outputs.json | jq -r .bastion_public_ip.value) 
    - >
      export CEPH_FSID=$( \
        ssh -T -o 'StrictHostKeyChecking no' -i ansible_rsa -l ansible \
        $BASTION_IP "ssh ceph1.ru-central1.internal 'sudo ceph fsid'" \
      )
    - >
      export CEPH_ADMIN_KEY=$( \
        ssh -T -o 'StrictHostKeyChecking no' -i ansible_rsa -l ansible \
        $BASTION_IP \
        "ssh ceph1.ru-central1.internal 'sudo ceph auth get client.admin'" | \
        grep 'key = ' | awk '{ print $3 }' \
      )
    - >
      export CEPH_KUBE_KEY=$( \
        ssh -T -o 'StrictHostKeyChecking no' -i ansible_rsa -l ansible \
        $BASTION_IP \
        "ssh ceph1.ru-central1.internal 'sudo ceph auth get-key client.kube'" \
      )
  script:
    - >
      ssh -T -o "StrictHostKeyChecking no" -i ansible_rsa -l ansible \
      ${BASTION_IP} CEPH_ADMIN_KEY=${CEPH_ADMIN_KEY} " \
        envsubst '\${CEPH_ADMIN_KEY}' \
        < ~/argocd/ceph/secret.yaml.template \
        > ~/argocd/ceph/secret.yaml \
      "
    - >
      ssh -T -o "StrictHostKeyChecking no" -i ansible_rsa -l ansible \
      ${BASTION_IP} SELECTEL_API_TOKEN=${SELECTEL_API_TOKEN} " \
        envsubst '\${SELECTEL_API_TOKEN}' \
        < ~/argocd/selectel-api-token.yml.template \
        > ~/argocd/selectel-api-token.yml; \
        envsubst '\${SELECTEL_API_TOKEN}' \
        < ~/argocd/ceph/secret.yaml.template \
        > ~/argocd/ceph/secret.yaml;
    - >
      ssh -T -o "StrictHostKeyChecking no" -i ansible_rsa -l ansible \
      ${BASTION_IP} CEPH_FSID=${CEPH_FSID} " \
        envsubst '\${CEPH_FSID}' \
        < ~/argocd/ceph/ceph.yaml.template \
        > ~/argocd/ceph/ceph.yaml; \
        envsubst '\${CEPH_FSID}' \
        < ~/argocd/ceph/storageclass.yaml.template \
        > ~/argocd/ceph/storageclass.yaml
    - >
      ssh -T -o "StrictHostKeyChecking no" -i ansible_rsa -l ansible \
      ${BASTION_IP} " \
        k apply -f ~/argocd/selectel-api-token.yml; \
        k label namespace argocd istio-injection=enabled; \
        k -n argocd patch cm argocd-cmd-params-cm \
          --patch-file ~/argocd/argo-patch.yaml; \
        k -n argocd scale deployment argocd-server --replicas=0; \
        sleep 5; \
        k -n argocd scale deployment argocd-server --replicas=1; \
        sleep 30; \
        k apply -f ~/argocd/ceph/ceph.yaml; \
        k apply -f ~/argocd/ceph/secret.yaml; \
        k apply -f ~/argocd/ceph/storageclass.yaml; \
        sleep 600; \
        k apply -f ~/argocd/root-projects.yaml; \ 
        k apply -f ~/argocd/root-applications.yaml; \
        "
